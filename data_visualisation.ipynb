{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de données\n",
    "\n",
    "inspiration : https://www.kaggle.com/code/datatattle/covid-19-tweets-eda-viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import defaultdict,Counter\n",
    "import string\n",
    "import seaborn as sns\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Création des dataframes d'entrainement et de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Corona_NLP_train.csv\", encoding = 'latin1')\n",
    "test = pd.read_csv(\"Corona_NLP_test.csv\", encoding = 'latin1')\n",
    "\n",
    "train['OriginalTweet']=train['OriginalTweet'].astype(str)\n",
    "train['Sentiment']=train['Sentiment'].astype(str)\n",
    "\n",
    "test['OriginalTweet']=test['OriginalTweet'].astype(str)\n",
    "test['Sentiment']=test['Sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des 5 premières ligne du dataframe d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des 5 premières ligne du dataframe de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre et du pourcentage de données manquantes du dataframe d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null= train.isnull().sum().sort_values(ascending=False)\n",
    "total =train.shape[0]\n",
    "percent_missing= (train.isnull().sum()/total).sort_values(ascending=False)\n",
    "\n",
    "missing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n",
    "\n",
    "missing_data.reset_index(inplace=True)\n",
    "missing_data= missing_data.rename(columns= { \"index\": \" column name\"})\n",
    " \n",
    "print (\"Null Values in each column:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre et du pourcentage de données manquantes du dataframe de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null= test.isnull().sum().sort_values(ascending=False)\n",
    "total =test.shape[0]\n",
    "percent_missing= (test.isnull().sum()/total).sort_values(ascending=False)\n",
    "\n",
    "missing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n",
    "\n",
    "missing_data.reset_index(inplace=True)\n",
    "missing_data= missing_data.rename(columns= { \"index\": \" column name\"})\n",
    " \n",
    "print (\"Null Values in each column:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total de tweets dans les donnees d'entrainement ainsi que du nombre d'utilisateurs uniques dans le dataframe d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total tweets in this data: {}'.format(train.shape[0]))\n",
    "print('Total Unique Users in this data: {}'.format(train['UserName'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total de tweets dans les donnees d'entrainement ainsi que du nombre d'utilisateurs uniques dans le dataframe de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total tweets in this data: {}'.format(test.shape[0]))\n",
    "print('Total Unique Users in this data: {}'.format(test['UserName'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage de la liste des differentes classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.Sentiment.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion de 5 à 3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train.OriginalTweet\n",
    "train[\"text\"] = train[\"text\"].astype(str)\n",
    "\n",
    "test['text'] = test.OriginalTweet\n",
    "test[\"text\"] = test[\"text\"].astype(str)\n",
    "\n",
    "def classes_def(x):\n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return \"positive\"\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return \"negative\"\n",
    "    elif x == \"Negative\":\n",
    "        return \"negative\"\n",
    "    elif x ==  \"Positive\":\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "    \n",
    "train['sentiment']=train['Sentiment'].apply(lambda x:classes_def(x))\n",
    "test['sentiment']=test['Sentiment'].apply(lambda x:classes_def(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total de donnees pour chaque classe pour les donnees d'entrainement et de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(1, 2, subplot_titles = ('Train set','Test set'))\n",
    "fig.update_layout(title_text = \"Number of data for each sentiment\")\n",
    "x = train.sentiment.value_counts()\n",
    "fig.add_trace(go.Bar(x = x.index, y = x.values, marker_color = ['#17C37B','#F92969','#FACA0C'], name = 'train'),row = 1,col = 1)\n",
    "x=test.sentiment.value_counts()\n",
    "fig.add_trace(go.Bar(x = x.index, y = x.values, marker_color = ['#17C37B','#F92969','#FACA0C'], name = 'test'),row = 1,col = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total de caracteres par tweet pour chaque classe pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=make_subplots(1,3)\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"positive\"]['text'].str.len()\n",
    "ax1.hist(tweet_len,color='#17C37B')\n",
    "ax1.set_title('Positive Sentiments')\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"negative\"]['text'].str.len()\n",
    "ax2.hist(tweet_len,color='#F92969')\n",
    "ax2.set_title('Negative Sentiments')\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"neutral\"]['text'].str.len()\n",
    "ax3.hist(tweet_len,color='#FACA0C')\n",
    "ax3.set_title('Neutral Sentiments')\n",
    "\n",
    "fig.suptitle('Characters in tweets for each sentiment')\n",
    "plt.savefig(\"out/characters_in_tweets_for_each_sentiment.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total de mots par tweet pour chaque classe pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"positive\"]['text'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(tweet_len,color='#17C37B')\n",
    "ax1.set_title('Positive Sentiments')\n",
    "\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"negative\"]['text'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(tweet_len,color='#F92969')\n",
    "ax2.set_title('Negative Sentiments')\n",
    "\n",
    "tweet_len=train[train['sentiment']==\"neutral\"]['text'].str.split().map(lambda x: len(x))\n",
    "ax3.hist(tweet_len,color='#FACA0C')\n",
    "ax3.set_title('Neutral Sentiments')\n",
    "\n",
    "fig.suptitle('Words in a tweet')\n",
    "plt.savefig(\"out/words_in_tweets_for_each_sentiment.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage de la longueur moyenne des mots dans chaque tweet pour chaque classe pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2, ax3)=plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "word=train[train['sentiment']==\"positive\"]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.histplot(word.map(lambda x: np.mean(x)),ax=ax1,color='#17C37B')\n",
    "ax1.set_title('Positive')\n",
    "\n",
    "\n",
    "word=train[train['sentiment']==\"negative\"]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.histplot(word.map(lambda x: np.mean(x)),ax=ax2,color='#F92969')\n",
    "ax2.set_title('Negative')\n",
    "\n",
    "word=train[train['sentiment']==\"neutral\"]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.histplot(word.map(lambda x: np.mean(x)),ax=ax3,color='#FACA0C')\n",
    "ax3.set_title('Neutral')\n",
    "\n",
    "fig.suptitle('Average word length in each tweet for each class')\n",
    "fig.savefig('out/Average word length in each tweet for each class.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(target):\n",
    "    corpus=[]\n",
    "    \n",
    "    for x in train[train['sentiment']==target]['text'].str.split():\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total d'utilisation de la ponctuation pour tous les tweets pour la classe \"Positive\" pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(\"positive\")\n",
    "\n",
    "dic=defaultdict(int)\n",
    "\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "\n",
    "x,y=zip(*dic.items())     \n",
    "plt.title(\"Total number of uses of punctuation for all tweets for positive sentiment\")\n",
    "plt.bar(x,y,color='#17C37B')\n",
    "plt.savefig(\"out/number_punctuation_positive.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total d'utilisation de la ponctuation pour tous les tweets pour la classe \"Negative\" pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(\"negative\")\n",
    "\n",
    "dic=defaultdict(int)\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "        \n",
    "x,y=zip(*dic.items())\n",
    "plt.title(\"Total number of uses of punctuation for all tweets for negative sentiment\")\n",
    "plt.bar(x,y,color='#F92969')\n",
    "plt.savefig(\"out/number_punctuation_negative.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage du nombre total d'utilisation de la ponctuation pour tous les tweets pour la classe \"Neutral\" pour les donnees d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(\"neutral\")\n",
    "\n",
    "dic=defaultdict(int)\n",
    "import string\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "        \n",
    "x,y=zip(*dic.items())\n",
    "plt.title(\"Total number of uses of punctuation for all tweets for neutral sentiment\")\n",
    "plt.bar(x,y,color='#FACA0C')\n",
    "plt.savefig(\"out/number_punctuation_neutral.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des mots les plus frequents pour chaque dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(words):\n",
    "    frequencies = {}\n",
    "    for word in words.split(' '):\n",
    "        if word in frequencies:\n",
    "            frequencies[word] += 1\n",
    "        else:\n",
    "            frequencies[word] = 1\n",
    "    return {key: value for key, value in sorted(frequencies.items(),key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(frequencies, title=''):\n",
    "    wordcloud = WordCloud(width=1000, height=800, background_color='white').generate_from_frequencies(frequencies)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(title, fontsize=30, fontweight='bold')\n",
    "    plt.savefig(\"out/\"+title+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des mots les plus frequents pour le dataframe d'entrainement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = len(train['OriginalTweet'])-1\n",
    "words = train['OriginalTweet'][index]\n",
    "word_cloud(get_frequencies(words), \"Most frequent word in the dataframe train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des mots les plus frequents pour le dataframe de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = len(test['OriginalTweet'])-1\n",
    "words = test['OriginalTweet'][index]\n",
    "word_cloud(get_frequencies(words), \"Most frequent word in the dataframe test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
