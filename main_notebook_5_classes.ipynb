{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9HjnVDmssa8",
    "outputId": "07cebb68-3af1-445f-cfbd-b40979e3fade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Collecting tweet-preprocessor\n",
      "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "#from os import chdir\n",
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount(\"/content/drive\", force_remount=True)\n",
    "#chdir(\"/content/drive/MyDrive/Eliott/files/\")\n",
    "\n",
    "#!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.22.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0.2)\n",
      "Requirement already satisfied: tweet-preprocessor in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\honorine\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-9SGvosr0_w"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LGn68XDZIm8L"
   },
   "outputs": [],
   "source": [
    "file_name_train = 'Corona_NLP_train.csv'\n",
    "file_name_test = 'Corona_NLP_test.csv'\n",
    "#3 classes\n",
    "X_train, y_train = pp.prepare_dataframe(file_name_train, False, lemmatising=False)\n",
    "X_test, y_test = pp.prepare_dataframe(file_name_test, False, lemmatising=False)\n",
    "#5 classes\n",
    "X_train_5, y_train_5 = pp.prepare_dataframe(file_name_train, True, lemmatising=False)\n",
    "X_test_5, y_test_5 = pp.prepare_dataframe(file_name_test, True, lemmatising=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_xUJTHaIm8M"
   },
   "source": [
    "On enlève : \n",
    "- Les URLS\n",
    "- Hashtags\n",
    "- Mentions\n",
    "- Mots réservés\n",
    "- Emojis et smileys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6tqgCANIm8N"
   },
   "source": [
    "- 35525 mots sans lemmatisation\n",
    "- 30794 avec lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMY7FfWTr1AI"
   },
   "source": [
    "# Recherche d'Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0KNjQ8imIm8O"
   },
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', GradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(max_iter=1000)),\n",
    "])\n",
    "\n",
    "pipeline_per = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', Perceptron()),\n",
    "])\n",
    "\n",
    "pipeline_svc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC(max_iter=10000)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "97TEYLlfIm8P"
   },
   "outputs": [],
   "source": [
    "models_and_params = {\n",
    "    \"SGD\" : { \"model\" : pipeline_sgd,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__alpha': np.linspace(1e-10, 1e-4, 40),  \n",
    "                        }\n",
    "    },\n",
    "    \"GB\" : { \"model\" : pipeline_gb,\n",
    "              \"params\" : {\n",
    "                    \"clf__learning_rate\": [0.1, 0.2,0.4,0.8],\n",
    "                    \"clf__n_estimators\":[1600]#,3200]\n",
    "                        }\n",
    "    },\n",
    "    \"RF\" : { \"model\" : pipeline_rf,\n",
    "              \"params\" : {\n",
    "                    'clf__n_estimators': [100, 200],   \n",
    "                    'clf__max_depth': [300,600,None],\n",
    "                    'clf__min_samples_leaf': [1, 2, 3],   \n",
    "                    'clf__min_samples_split': [16, 32, 64],\n",
    "                    'clf__max_features': ['log2', 'sqrt'],\n",
    "                    'clf__criterion': ['gini', 'entropy']\n",
    "                        }\n",
    "    },\n",
    "    \"LR\" : { \"model\" : pipeline_lr,\n",
    "              \"params\" : {\n",
    "                    'clf__C': [20,10, 1],\n",
    "                    'clf__tol': np.linspace(1e-12,1e-6,20)\n",
    "                        }\n",
    "    },\n",
    "    \"PER\" : { \"model\" : pipeline_per,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__alpha': np.linspace(1e-8, 1e-4, 100),\n",
    "                        }\n",
    "    },\n",
    "    \"SVC\" : { \"model\" : pipeline_svc,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__loss': ['hinge', 'squared_hinge'],\n",
    "                    'clf__dual' : [False,True]\n",
    "                        }\n",
    "    }\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "En34oFshCc-r"
   },
   "outputs": [],
   "source": [
    "def grid_Search(model_name,subset=-1):\n",
    "\n",
    "    model = models_and_params[model_name][\"model\"]\n",
    "    parameters = models_and_params[model_name][\"params\"]\n",
    "\n",
    "    grid_clf = GridSearchCV(model, parameters,  scoring='accuracy', verbose=1 ,n_jobs=-1)\n",
    "    \n",
    "    if subset==-1:\n",
    "        grid_clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        grid_clf.fit(X_train[:subset], y_train[:subset])\n",
    "\n",
    "\n",
    "    print(\"Best Score: \", grid_clf.best_score_)\n",
    "    print(\"Best Params: \", grid_clf.best_params_)\n",
    "\n",
    "    return grid_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVVyneGfIm8Q"
   },
   "source": [
    "### Saving Hyperparameters in JSON\n",
    "\n",
    "We will first load old weights and updates only if needed. Then we can use the model with best params in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JqHmEnxTIm8Q"
   },
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    dico = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQD0wO_uIm8R"
   },
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHzMRehgIm8R",
    "outputId": "cdf4128e-f6f5-48c4-b5e5-90309c001fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Best Score:  0.8807008312810172\n",
      "Best Params:  {'clf__alpha': 1.28206e-05, 'clf__penalty': 'l1'}\n",
      "CPU times: user 29 s, sys: 4.25 s, total: 33.2 s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_sgd = grid_Search(\"SGD\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5vbIP8kIm8R"
   },
   "outputs": [],
   "source": [
    "dico['SGD'] = grid_sgd.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Bbu1S9f9Xo9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-R5-LqYCc-s"
   },
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdnkSlvdIm8S",
    "outputId": "94fc131a-d1e4-4850-b8b4-4d19810ac2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Score:  0.8391769441865644\n",
      "Best Params:  {'clf__learning_rate': 0.4, 'clf__n_estimators': 1600}\n",
      "CPU times: user 33min 38s, sys: 7.7 s, total: 33min 46s\n",
      "Wall time: 3h 40min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_gb = grid_Search(\"GB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TQLvEgp-Im8S"
   },
   "outputs": [],
   "source": [
    "dico['GB'] = grid_gb.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf8DtN5iCc-t"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5bHoZ9pCc-t",
    "outputId": "e9bf3431-b7a6-48b3-8f56-979cb31c1c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7047644196092446\n",
      "Best Params:  {'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 32, 'clf__n_estimators': 200}\n",
      "CPU times: user 2min 29s, sys: 14 s, total: 2min 43s\n",
      "Wall time: 2h 30min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf = grid_Search(\"RF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PumLEUuAIm8T"
   },
   "outputs": [],
   "source": [
    "dico['RF'] = grid_rf.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hybcOGPZCc-t"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKt3pLZBCc-u",
    "outputId": "05a7711e-20ba-4d8f-eb89-ff9b883c295a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8230677619122002\n",
      "Best Params:  {'clf__C': 10, 'clf__tol': 1e-12}\n",
      "CPU times: user 1min 20s, sys: 2min 15s, total: 3min 35s\n",
      "Wall time: 36min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_lr = grid_Search(\"LR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQK-LftNIm8T"
   },
   "outputs": [],
   "source": [
    "dico['LR'] = grid_lr.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCMXN9M8Cc-u"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPGHPCruCc-v",
    "outputId": "61a52771-ba29-48da-f0f5-86bc9f88215c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "Best Score:  0.818353925564533\n",
      "Best Params:  {'clf__alpha': 3.04e-06, 'clf__penalty': 'l1'}\n",
      "CPU times: user 1min 10s, sys: 7.51 s, total: 1min 17s\n",
      "Wall time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_per = grid_Search(\"PER\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Hd5CjXKfIm8U"
   },
   "outputs": [],
   "source": [
    "dico['Perceptron'] = grid_per.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1su0mDwMIm8U"
   },
   "source": [
    "#### Observation \n",
    "\n",
    "La regression logistique n'est qu'un perceptron avec une sigmoid en fonction d'activation.\n",
    "On voit que la Regression Logistique a de meilleures performances à l'issue de la recherche d'hyperparamètres mais pas de loin. Par ailleurs le temps d'entrainement est considérablement plus élevé pour la regression logistique (du au calcul de l'exponentiel). Nous verrons par la suite quel modèle il est préférable de conserver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cy0mgWVCc-v"
   },
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9K-4Ufu3Cc-v",
    "outputId": "e9e94094-e0f1-45d8-c6d0-fc5f9c5c8748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\", line 272, in fit\n",
      "    sample_weight=sample_weight,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 1026, in _get_liblinear_solver_type\n",
      "    % (error_string, penalty, loss, dual)\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83094003 0.86891657        nan\n",
      " 0.82693114        nan        nan 0.83091573        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.868916566574562\n",
      "Best Params:  {'clf__dual': False, 'clf__loss': 'squared_hinge', 'clf__penalty': 'l1'}\n",
      "CPU times: user 11.5 s, sys: 524 ms, total: 12.1 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_svc = grid_Search(\"SVC\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kllEfjEeIm8U"
   },
   "outputs": [],
   "source": [
    "dico['SVC'] = grid_svc.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXpV5M9IIm8U"
   },
   "source": [
    "### Charging the best parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ct7BBebdCc-w"
   },
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "data_sgd = data['SGD']\n",
    "data_rf = data['RF']\n",
    "data_gb = data['GB']\n",
    "data_lr = data['LR']\n",
    "data_per = data['Perceptron']\n",
    "data_svc = data['SVC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efhYhzvsIm8V"
   },
   "source": [
    "### Training on all training data and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rjoag_IAIm8V"
   },
   "outputs": [],
   "source": [
    "def testing(model):\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train,predictions_train )\n",
    "    accuracy_test = accuracy_score(y_test,predictions_test )\n",
    "    \n",
    "    print(f\"train_accuracy : {accuracy_train} \\ntest_accuracy : {accuracy_test}  \")\n",
    "    accuracy = []\n",
    "    accuracy.append(accuracy_train)\n",
    "    accuracy.append(accuracy_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_5_classes(model):\n",
    "    predictions_train = model.predict(X_train_5)\n",
    "    predictions_test = model.predict(X_test_5)\n",
    "    accuracy_train = accuracy_score(y_train_5,predictions_train )\n",
    "    accuracy_test = accuracy_score(y_test_5,predictions_test )\n",
    "    \n",
    "    print(f\"train_accuracy for 5 classes : {accuracy_train} \\ntest_accuracy for 5 classes: {accuracy_test}  \")\n",
    "    accuracy = []\n",
    "    accuracy.append(accuracy_train)\n",
    "    accuracy.append(accuracy_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes = []\n",
    "accuracy_5_classes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c58mITNcIm8V"
   },
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FozzlotYCc-w",
    "outputId": "075c1206-e5dd-42e1-ab17-150125522e07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1,\n",
       "                               penalty='l1'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd_best = pipeline_sgd\n",
    "model_sgd_best.set_params(**data_sgd,clf__n_jobs=-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nB_Uisu1Im8V",
    "outputId": "4fbe6dd6-da61-4b2c-ff25-360ab59e89c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1,\n",
       "                               penalty='l1'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Si on a fait la recherche avant, on prend le best modèle,\n",
    "\n",
    "Sinon, on reconstruit le modèle avec les best paramètres et on le fit à toutes les données d'entrainement. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model_sgd_best.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qLjHzHrIm8W",
    "outputId": "49b512c7-6cdd-4e0f-bbb3-dae88f1b457f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9395728551643706 \n",
      "test_accuracy : 0.8746708794102159  \n"
     ]
    }
   ],
   "source": [
    "sgd_3_classes = testing(model_sgd_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"sgd\")\n",
    "accuracy_3_classes_line.append(sgd_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1,\n",
       "                               penalty='l1'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_sgd_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.8270039118497461 \n",
      "test_accuracy for 5 classes: 0.5992627698788836  \n"
     ]
    }
   ],
   "source": [
    "sgd_5_classes = testing_5_classes(model_sgd_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"sgd\")\n",
    "accuracy_5_classes_line.append(sgd_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr9nBCXvIm8W"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGouwXZ_Cc-x",
    "outputId": "d811fee4-defa-4145-89fa-99505eb06fa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=600, max_features='sqrt',\n",
       "                                        min_samples_leaf=2,\n",
       "                                        min_samples_split=32, n_jobs=-1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_best = pipeline_rf\n",
    "model_rf_best.set_params(**data_rf,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdEu7AlyCc-x",
    "outputId": "8b7d8c26-ba71-4593-e846-c0b57c4ef8b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=600, max_features='sqrt',\n",
       "                                        min_samples_leaf=2,\n",
       "                                        min_samples_split=32, n_jobs=-1))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWtUmtDsCc-x",
    "outputId": "455bbb44-774b-4cfe-eb76-8f77ce6593ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.8651262239716209 \n",
      "test_accuracy : 0.6924697209057399  \n"
     ]
    }
   ],
   "source": [
    "rf_3_classes = testing(model_rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"rf\")\n",
    "accuracy_3_classes_line.append(rf_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=600, max_features='sqrt',\n",
       "                                        min_samples_leaf=2,\n",
       "                                        min_samples_split=32, n_jobs=-1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.8289476881210973 \n",
      "test_accuracy for 5 classes: 0.4673512374934176  \n"
     ]
    }
   ],
   "source": [
    "rf_5_classes = testing_5_classes(model_rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"rf\")\n",
    "accuracy_5_classes_line.append(rf_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ltx6agFIm8W"
   },
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBkq5EjbIm8X",
    "outputId": "9c50fafd-d7c3-4ce9-a885-69a95a71e745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb_best = pipeline_gb\n",
    "model_gb_best.set_params(**data_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhbG6NHjIm8X",
    "outputId": "34bf2452-5866-4aac-984f-68f907ac1473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_gb_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IAbPNE1Im8X",
    "outputId": "e78a9d35-acdc-446e-9132-bee2324fe8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9152513545690891 \n",
      "test_accuracy : 0.8272775144813059  \n"
     ]
    }
   ],
   "source": [
    "gb_3_classes = testing(model_gb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"gb\")\n",
    "accuracy_3_classes_line.append(gb_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_gb_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.8844910950749568 \n",
      "test_accuracy for 5 classes: 0.590047393364929  \n"
     ]
    }
   ],
   "source": [
    "gb_5_classes = testing_5_classes(model_gb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"gb\")\n",
    "accuracy_5_classes_line.append(gb_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pOf07uNIm8X"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lX1hcdBjIm8X",
    "outputId": "284c7703-a045-4ef4-a17f-192b7dc612a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, max_iter=1000, n_jobs=-1,\n",
       "                                    tol=1e-08))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_best = pipeline_lr\n",
    "model_lr_best.set_params(**data_lr,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcONRPWqIm8X",
    "outputId": "aa219fdc-bb6f-49e3-bcc6-19394ad8744d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, max_iter=1000, n_jobs=-1,\n",
       "                                    tol=1e-08))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aWokKTIIm8X",
    "outputId": "639eb006-823f-47af-e380-bdd57f913cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9760429574555969 \n",
      "test_accuracy : 0.8317535545023697  \n"
     ]
    }
   ],
   "source": [
    "lr_3_classes = testing(model_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"lr\")\n",
    "accuracy_3_classes_line.append(lr_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, max_iter=1000, n_jobs=-1,\n",
       "                                    tol=1e-08))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.9501664358432345 \n",
      "test_accuracy for 5 classes: 0.6040021063717746  \n"
     ]
    }
   ],
   "source": [
    "lr_5_classes = testing_5_classes(model_lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"lr\")\n",
    "accuracy_5_classes_line.append(lr_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8iVyZvUIm8X"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpJKR5-CIm8Y",
    "outputId": "a2e57fd5-f0c7-410e-dc36-b087e4cd1967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, n_jobs=-1,\n",
       "                            penalty='l1'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_per_best = pipeline_per\n",
    "model_per_best.set_params(**data_per,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdazS8r9Im8Y",
    "outputId": "401da1d0-0704-4969-c6e6-a2053c2c9630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, n_jobs=-1,\n",
       "                            penalty='l1'))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_per_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQWvx1CJIm8Y",
    "outputId": "c5418f81-2fab-41b3-c35e-5c1db221937d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9071603858395899 \n",
      "test_accuracy : 0.814902580305424  \n"
     ]
    }
   ],
   "source": [
    "per_3_classes = testing(model_per_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"per\")\n",
    "accuracy_3_classes_line.append(per_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, n_jobs=-1,\n",
       "                            penalty='l1'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_per_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.7100371747211895 \n",
      "test_accuracy for 5 classes: 0.49921011058451814  \n"
     ]
    }
   ],
   "source": [
    "per_5_classes = testing_5_classes(model_per_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"per\")\n",
    "accuracy_5_classes_line.append(per_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1O2dupiIm8Y"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG0A4VREIm8Y",
    "outputId": "1d42cb61-fba2-4f45-e4fb-4fe0e98c6a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc_best = pipeline_svc\n",
    "model_svc_best.set_params(**data_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSG2qg6GIm8Y",
    "outputId": "c5ac5995-9001-4f2b-e6ae-121e34e32423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1NV_zYeIm8Z",
    "outputId": "ef2e7adb-ba68-4790-dad0-46693c1c47a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9475423378769103 \n",
      "test_accuracy : 0.8670352817272249  \n"
     ]
    }
   ],
   "source": [
    "svc_3_classes = testing(model_svc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"svc\")\n",
    "accuracy_3_classes_line.append(svc_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc_best.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.8556746118521759 \n",
      "test_accuracy for 5 classes: 0.588204318062138  \n"
     ]
    }
   ],
   "source": [
    "svc_5_classes = testing_5_classes(model_svc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"svc\")\n",
    "accuracy_5_classes_line.append(svc_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igWU2A4PIm8Z"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "aSjG01FhCc-x"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "86JLNLKor1AL"
   },
   "outputs": [],
   "source": [
    "clf1 = model_sgd_best\n",
    "\n",
    "clf2 = model_rf_best\n",
    "\n",
    "clf3 = model_gb_best\n",
    "\n",
    "clf4 = model_lr_best\n",
    "\n",
    "clf5 = model_per_best\n",
    "\n",
    "clf6 = model_svc_best\n",
    "\n",
    "\n",
    "eclf1 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('rf', clf2), ('gb', clf3), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n",
    "\n",
    "eclf2 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wiWZkZ7Im8Z",
    "outputId": "c973ed4a-2b45-4558-9fee-9a4b80d4039e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('rf',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               RandomForestClassifier(max_depth=600,\n",
       "                                                                      max_features='sqrt',\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=32,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             ('gb',\n",
       "                              Pipeline(steps=[(...\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fw_BUQQSIm8Z",
    "outputId": "a6126b36-066c-47f6-99a6-4a9e5e5ae06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9582331073693418 \n",
      "test_accuracy : 0.8686150605581885  \n"
     ]
    }
   ],
   "source": [
    "eclf1_3_classes = testing(eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"vc1\")\n",
    "accuracy_3_classes_line.append(eclf1_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0T0t23GRIm8Z",
    "outputId": "7274c239-5e85-4f7e-f3e3-b4589415a77c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('lr',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P69br2jIm8a",
    "outputId": "0d392b84-575f-48bb-e8e0-b375619f367b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9572855164370581 \n",
      "test_accuracy : 0.8636124275934702  \n"
     ]
    }
   ],
   "source": [
    "eclf2_3_classes = testing(eclf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3_classes_line = []\n",
    "accuracy_3_classes_line.append(\"vc2\")\n",
    "accuracy_3_classes_line.append(eclf2_3_classes)\n",
    "accuracy_3_classes.append(accuracy_3_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzMDFjR6MbDc"
   },
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('rf',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               RandomForestClassifier(max_depth=600,\n",
       "                                                                      max_features='sqrt',\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=32,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             ('gb',\n",
       "                              Pipeline(steps=[(...\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf1.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.9143037636368054 \n",
      "test_accuracy for 5 classes: 0.6142706687730385  \n"
     ]
    }
   ],
   "source": [
    "eclf1_5_classes = testing_5_classes(eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"vc1\")\n",
    "accuracy_5_classes_line.append(eclf1_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('lr',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf2.fit(X_train_5,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy for 5 classes : 0.8801175984644167 \n",
      "test_accuracy for 5 classes: 0.5955766192733017  \n"
     ]
    }
   ],
   "source": [
    "eclf2_5_classes = testing_5_classes(eclf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5_classes_line = []\n",
    "accuracy_5_classes_line.append(\"vc2\")\n",
    "accuracy_5_classes_line.append(eclf2_5_classes)\n",
    "accuracy_5_classes.append(accuracy_5_classes_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison du train et du test accuracy pour 3 classes et pour 5 classes pour les méthodes :\n",
    "- SGD,\n",
    "- Random Forest,\n",
    "- Gradient Boosting,\n",
    "- Logistic Regression,\n",
    "- Perceptron,\n",
    "- SVC et\n",
    "- Voting Classifier de 2 versions :\n",
    "    - SGD, Random Forest, Gradient Boosting, Logistic Regression, Perceptron, SVC\n",
    "    - SGD, Logistic Regression, Perceptron, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inter_train = []\n",
    "list_inter_test = []\n",
    "for i in range(len(accuracy_3_classes)):\n",
    "    list_inter_train.append(accuracy_3_classes[i][1][0])\n",
    "    list_inter_test.append(accuracy_3_classes[i][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inter_train.sort()\n",
    "list_inter_train.reverse()\n",
    "list_inter_test.sort()\n",
    "list_inter_test.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le classement des methodes pour en fonction du meilleur \u001b[1mTrain accuracy\u001b[0m pour \u001b[1m3\u001b[0m classes est :\n",
      "1er Logistic Regression pour le train accuracy:  0.9760429574555969\n",
      "2e Voting Classifier 1 pour le train accuracy:   0.9582331073693418\n",
      "3e Voting Classifier 2 pour le train accuracy:   0.9572855164370581\n",
      "4e SVC avec pour le train accuracy:              0.9475423378769103\n",
      "5e SGD avec pour le train accuracy:              0.9395728551643706\n",
      "6e Gradient Boosting pour le train accuracy:     0.9152513545690891\n",
      "7e Perceptron avec pour le train accuracy:       0.9071603858395899\n",
      "8e Random Forest pour le train accuracy:         0.8651262239716209\n"
     ]
    }
   ],
   "source": [
    "print(\"Le classement des methodes pour en fonction du meilleur \\033[1mTrain accuracy\\033[0m pour \\033[1m3\\033[0m classes est :\")\n",
    "print(\"1er Logistic Regression pour le train accuracy: \", list_inter_train[0])\n",
    "print(\"2e Voting Classifier 1 pour le train accuracy:  \", list_inter_train[1])\n",
    "print(\"3e Voting Classifier 2 pour le train accuracy:  \", list_inter_train[2])\n",
    "print(\"4e SVC avec pour le train accuracy:             \", list_inter_train[3])\n",
    "print(\"5e SGD avec pour le train accuracy:             \", list_inter_train[4])\n",
    "print(\"6e Gradient Boosting pour le train accuracy:    \", list_inter_train[5])\n",
    "print(\"7e Perceptron avec pour le train accuracy:      \", list_inter_train[6])\n",
    "print(\"8e Random Forest pour le train accuracy:        \", list_inter_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le classement des methodes pour en fonction du meilleur \u001b[1mTest accuracy\u001b[0m pour \u001b[1m3\u001b[0m classes est :\n",
      "1er SGD pour le train accuracy:                      0.8746708794102159\n",
      "2e Voting Classifier 1 pour le train accuracy:       0.8686150605581885\n",
      "3e SVC pour le train accuracy:                       0.8670352817272249\n",
      "4e Voting Classifier 2 avec pour le train accuracy:  0.8636124275934702\n",
      "5e Logistic Regression avec pour le train accuracy:  0.8317535545023697\n",
      "6e Gradient Boosting pour le train accuracy:         0.8272775144813059\n",
      "7e Perceptron avec pour le train accuracy:           0.814902580305424\n",
      "8e Random Forest pour le train accuracy:             0.6924697209057399\n"
     ]
    }
   ],
   "source": [
    "print(\"Le classement des methodes pour en fonction du meilleur \\033[1mTest accuracy\\033[0m pour \\033[1m3\\033[0m classes est :\")\n",
    "print(\"1er SGD pour le train accuracy:                     \", list_inter_test[0])\n",
    "print(\"2e Voting Classifier 1 pour le train accuracy:      \", list_inter_test[1])\n",
    "print(\"3e SVC pour le train accuracy:                      \", list_inter_test[2])\n",
    "print(\"4e Voting Classifier 2 avec pour le train accuracy: \", list_inter_test[3])\n",
    "print(\"5e Logistic Regression avec pour le train accuracy: \", list_inter_test[4])\n",
    "print(\"6e Gradient Boosting pour le train accuracy:        \", list_inter_test[5])\n",
    "print(\"7e Perceptron avec pour le train accuracy:          \", list_inter_test[6])\n",
    "print(\"8e Random Forest pour le train accuracy:            \", list_inter_test[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inter5_train = []\n",
    "list_inter5_test = []\n",
    "for i in range(len(accuracy_5_classes)):\n",
    "    list_inter5_train.append(accuracy_5_classes[i][1][0])\n",
    "    list_inter5_test.append(accuracy_5_classes[i][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inter5_train.sort()\n",
    "list_inter5_train.reverse()\n",
    "list_inter5_test.sort()\n",
    "list_inter5_test.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le classement des methodes pour en fonction du meilleur \u001b[1mTrain accuracy\u001b[0m pour \u001b[1m5\u001b[0m classes est :\n",
      "1er Logistic Regression avec pour accuracy:  0.9501664358432345\n",
      "2e Voting Classifier 2 avec pour accuracy:   0.9143037636368054\n",
      "3e Gradient Boosting avec pour accuracy:     0.8844910950749568\n",
      "4e Voting Classifier 1 avec pour accuracy:   0.8801175984644167\n",
      "5e SVC avec pour accuracy:                   0.8556746118521759\n",
      "6e Random Forest avec pour accuracy:         0.8289476881210973\n",
      "7e SGD avec pour accuracy:                   0.8270039118497461\n",
      "8e Perceptron avec pour accuracy:            0.7100371747211895\n"
     ]
    }
   ],
   "source": [
    "print(\"Le classement des methodes pour en fonction du meilleur \\033[1mTrain accuracy\\033[0m pour \\033[1m5\\033[0m classes est :\")\n",
    "print(\"1er Logistic Regression avec pour accuracy: \", list_inter5_train[0])\n",
    "print(\"2e Voting Classifier 2 avec pour accuracy:  \", list_inter5_train[1])\n",
    "print(\"3e Gradient Boosting avec pour accuracy:    \", list_inter5_train[2])\n",
    "print(\"4e Voting Classifier 1 avec pour accuracy:  \", list_inter5_train[3])\n",
    "print(\"5e SVC avec pour accuracy:                  \", list_inter5_train[4])\n",
    "print(\"6e Random Forest avec pour accuracy:        \", list_inter5_train[5])\n",
    "print(\"7e SGD avec pour accuracy:                  \", list_inter5_train[6])\n",
    "print(\"8e Perceptron avec pour accuracy:           \", list_inter5_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le classement des methodes pour en fonction du meilleur \u001b[1mTest accuracy\u001b[0m pour \u001b[1m5\u001b[0m classes est :\n",
      "1er Voting Classifier 2 avec pour accuracy:  0.6142706687730385\n",
      "2e Logistic Regression avec pour accuracy:   0.6040021063717746\n",
      "3e SGD avec pour accuracy:                   0.5992627698788836\n",
      "4e Voting Classifier 1 avec pour accuracy:   0.5955766192733017\n",
      "5e Gradient Boosting avec pour accuracy:     0.590047393364929\n",
      "6e SVC avec pour accuracy:                   0.588204318062138\n",
      "7e Perceptron avec pour accuracy:            0.49921011058451814\n",
      "8e Random Forest avec pour accuracy:         0.4673512374934176\n"
     ]
    }
   ],
   "source": [
    "print(\"Le classement des methodes pour en fonction du meilleur \\033[1mTest accuracy\\033[0m pour \\033[1m5\\033[0m classes est :\")\n",
    "print(\"1er Voting Classifier 2 avec pour accuracy: \", list_inter5_test[0])\n",
    "print(\"2e Logistic Regression avec pour accuracy:  \", list_inter5_test[1])\n",
    "print(\"3e SGD avec pour accuracy:                  \", list_inter5_test[2])\n",
    "print(\"4e Voting Classifier 1 avec pour accuracy:  \", list_inter5_test[3])\n",
    "print(\"5e Gradient Boosting avec pour accuracy:    \", list_inter5_test[4])\n",
    "print(\"6e SVC avec pour accuracy:                  \", list_inter5_test[5])\n",
    "print(\"7e Perceptron avec pour accuracy:           \", list_inter5_test[6])\n",
    "print(\"8e Random Forest avec pour accuracy:        \", list_inter5_test[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi on peut remarquer qu'en terme de **Train accuracy** le classement des 8 méthodes n'est pas le même pour 5 classes ou 3 classes. La 1ere méthode est la même mais pas le reste.\n",
    "\n",
    "- 3 classes:\n",
    "    - 1er Logistic Regression\n",
    "    - 2e Voting Classifier 1\n",
    "    - 3e Voting Classifier 2\n",
    "    - 4e SVC\n",
    "    - 5e SGD\n",
    "    - 6e Gradient Boosting\n",
    "    - 7e Perceptron\n",
    "    - 8e Random Forest\n",
    "\n",
    "- 5 classes :\n",
    "    - 1er Logistic Regression\n",
    "    - 2e Voting Classifier 2\n",
    "    - 3e Gradient Boosting\n",
    "    - 4e Voting Classifier 1\n",
    "    - 5e SVC\n",
    "    - 6e Random Forest\n",
    "    - 7e SGD\n",
    "    - 8e Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi on peut remarquer qu'en terme de **Test accuracy** le classement des 8 méthodes n'est pas le même pour 5 classes ou 3 classes. La 7e et 8e méthode sont les mêmes mais pas le reste.\n",
    "\n",
    "- 3 classes :\n",
    "    - 1er SGD\n",
    "    - 2e Voting Classifier 1\n",
    "    - 3e SVC\n",
    "    - 4e Voting Classifier 2\n",
    "    - 5e Logistic Regression\n",
    "    - 6e Gradient Boosting\n",
    "    - 7e Perceptron\n",
    "    - 8e Random Forest\n",
    "\n",
    "- 5 classes : \n",
    "    - 1er Voting Classifier 2\n",
    "    - 2e Logistic Regression\n",
    "    - 3e SGD\n",
    "    - 4e Voting Classifier 1\n",
    "    - 5e Gradient Boosting\n",
    "    - 6e SVC\n",
    "    - 7e Perceptron\n",
    "    - 8e Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdLQ58gVIm8a"
   },
   "source": [
    "### Tests perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4X_wIsASIm8a"
   },
   "outputs": [],
   "source": [
    "tests_perso = [\"I think covid is the most horrible threat we ever faced\",\n",
    "                \"I love covid, thanks to it I can see my family much more often and I don't have to comute as much\",\n",
    "                \"I would love to come to your birthday party, but I got covid, I have to stay confined\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjtuAMrAIm8a"
   },
   "outputs": [],
   "source": [
    "predictions_out = eclf2.predict(tests_perso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISxBcyP0Im8a",
    "outputId": "07019939-277f-4afc-ac29-87be2c393f89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_out"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "main_notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "822dd2d5dd360abba25557036e653898358cd5c8dbb7b3b755070434497e6489"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
