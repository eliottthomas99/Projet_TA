{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "d9HjnVDmssa8"
   },
   "outputs": [],
   "source": [
    "# from os import chdir\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# chdir(\"/content/drive/MyDrive/Eliott/files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "v-9SGvosr0_w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train = 'Corona_NLP_train.csv'\n",
    "file_name_test = 'Corona_NLP_test.csv'\n",
    "X_train, y_train = pp.prepare_dataframe(file_name_train,lemmatising=False)\n",
    "X_test, y_test = pp.prepare_dataframe(file_name_test,lemmatising=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève : \n",
    "- Les URLS\n",
    "- Hashtags\n",
    "- Mentions\n",
    "- Mots réservés\n",
    "- Emojis et smileys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 35525 mots sans lemmatisation\n",
    "- 30794 avec lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "\n",
    "On commence par vectoriser les données textuelles sous forme de tfidf. On se retrouve avec une sorte de one-hot vector pour chaque mot présent dans le corpus  total de tweets. La valeur pour chaque mot est le nombre de fois que le mot apparait dans le tweet divisé par le nombre de fois dans tous les tweets (importance locale / fréquence totale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 35525)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_vect = vectorizer.fit(X_train)\n",
    "X_vect = vectorizer.transform(X_train)\n",
    "X_vect_test = vectorizer.transform(X_test)\n",
    "\n",
    "X_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "\n",
    "On va augmenter syntétiquement les données pour équilibrer les classes et améliorer les performances globales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    18046\n",
      "-1    15398\n",
      " 0     7713\n",
      "Name: Sentiment_Number, dtype: int64\n",
      "-1    1633\n",
      " 1    1546\n",
      " 0     619\n",
      "Name: Sentiment_Number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMY7FfWTr1AI"
   },
   "source": [
    "# Recherche d'Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = SGDClassifier()\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_per = Perceptron()\n",
    "model_svc = LinearSVC(max_iter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_params = {\n",
    "    \"SGD\" : { \"model\" : model_sgd,\n",
    "              \"params\" : {\n",
    "                    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'alpha': np.linspace(1e-7, 1e-4, 20),  \n",
    "                        }\n",
    "    },\n",
    "    \"GB\" : { \"model\" : model_gb,\n",
    "              \"params\" : {\n",
    "                    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "                    \"n_estimators\":[10,50,100,200,400,800]\n",
    "                        }\n",
    "    },\n",
    "    \"RF\" : { \"model\" : model_rf,\n",
    "              \"params\" : {\n",
    "                    'n_estimators': [10, 100],   \n",
    "                    'max_depth': [10 ,150,300,600],\n",
    "                    'min_samples_leaf': [1, 2, 3],   \n",
    "                    'min_samples_split': [4, 8, 16, 32],\n",
    "                    'max_features': ['log2', 'sqrt'],\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                    'warm_start': [True, False] \n",
    "                        }\n",
    "    },\n",
    "    \"LR\" : { \"model\" : model_lr,\n",
    "              \"params\" : {\n",
    "                    'C': [100, 80, 40,20,10, 1.0],\n",
    "                    'tol': np.linspace(1e-8,1e-4,15)\n",
    "                        }\n",
    "    },\n",
    "    \"PER\" : { \"model\" : model_per,\n",
    "              \"params\" : {\n",
    "                    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'alpha': np.linspace(1e-8, 1e-4, 20),\n",
    "                        }\n",
    "    },\n",
    "    \"SVC\" : { \"model\" : model_svc,\n",
    "              \"params\" : {\n",
    "                    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'loss': ['hinge', 'squared_hinge'],\n",
    "                    'dual' : [False,True]\n",
    "                        }\n",
    "    }\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "En34oFshCc-r"
   },
   "outputs": [],
   "source": [
    "def grid_search(model_name,X_search,Y_search):\n",
    "\n",
    "    model = models_and_params[model_name][\"model\"]\n",
    "    parameters = models_and_params[model_name][\"params\"]\n",
    "\n",
    "    grid_clf = GridSearchCV(model, parameters,  scoring='accuracy', verbose=1 ,n_jobs=-1)\n",
    "    \n",
    "    grid_clf.fit(X_search, Y_search)\n",
    "\n",
    "    print(\"Best Score: \", grid_clf.best_score_)\n",
    "    print(\"Best Params: \", grid_clf.best_params_)\n",
    "\n",
    "    return grid_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Hyperparameters in JSON\n",
    "\n",
    "We will first load old weights and updates only if needed. Then we can use the model with best params in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    dico = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8786112322291502\n",
      "Best Params:  {'alpha': 1.5873684210526315e-05, 'penalty': 'l1'}\n",
      "CPU times: user 1.96 s, sys: 3.3 s, total: 5.26 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_sgd = grid_search(\"SGD\",X_vect,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8908717001978491\n",
      "Best Params:  {'alpha': 1.0615789473684212e-05, 'penalty': 'l1'}\n",
      "CPU times: user 2.49 s, sys: 3.18 s, total: 5.66 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_sgd_smote = grid_search(\"SGD\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SGD'] = grid_sgd_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-R5-LqYCc-s"
   },
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Score:  0.602\n",
      "Best Params:  {'learning_rate': 0.2, 'n_estimators': 800}\n",
      "CPU times: user 18.5 s, sys: 15.5 ms, total: 18.5 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_gb = grid_search(\"GB\",X_vect[:1000],y_train[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Js4osvIVCc-s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Score:  0.8167019453701956\n",
      "Best Params:  {'learning_rate': 0.2, 'n_estimators': 800}\n",
      "CPU times: user 9min 13s, sys: 22.9 ms, total: 9min 13s\n",
      "Wall time: 1h 35min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_gb = grid_search(\"GB\",X_vect[:100],y_train[:100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "GB_param = {\n",
    "    \"gb_clf__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"gb_clf__n_estimators\":[10,50,100,200,400,800]\n",
    "    }\n",
    "\n",
    "pipeline_gradient_boosting = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('gb_clf', GradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "gb_clf = GridSearchCV(pipeline_gradient_boosting, GB_param, scoring='accuracy', verbose=1 ,n_jobs=-1)\n",
    "\n",
    "gb_best = gb_clf.fit(X_train[:1000], y_train[:1000])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.5900000000000001\n",
      "Best Params:  {'gb_clf__learning_rate': 0.2, 'gb_clf__n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", gb_clf.best_score_)\n",
    "print(\"Best Params: \", gb_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Score:  0.824263698727705\n",
      "Best Params:  {'learning_rate': 0.2, 'n_estimators': 800}\n",
      "CPU times: user 11min 48s, sys: 230 ms, total: 11min 48s\n",
      "Wall time: 1h 43min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_gb_smote = grid_search(\"GB\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['GB'] = grid_gb_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf8DtN5iCc-t"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P5bHoZ9pCc-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n",
      "Best Score:  0.6936605598380768\n",
      "Best Params:  {'criterion': 'gini', 'max_depth': 600, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "CPU times: user 19 s, sys: 1.2 s, total: 20.2 s\n",
      "Wall time: 1h 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf = grid_search(\"RF\",X_vect,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n",
      "Best Score:  0.748994306773667\n",
      "Best Params:  {'criterion': 'entropy', 'max_depth': 600, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 32, 'n_estimators': 100, 'warm_start': False}\n",
      "CPU times: user 22.6 s, sys: 1.39 s, total: 24 s\n",
      "Wall time: 1h 27min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf_smote = grid_search(\"RF\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['RF'] = grid_rf_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hybcOGPZCc-t"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NKt3pLZBCc-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Score:  0.8231163380186238\n",
      "Best Params:  {'C': 10, 'tol': 1e-08}\n",
      "CPU times: user 1min 12s, sys: 3min 38s, total: 4min 51s\n",
      "Wall time: 34min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_lr = grid_search(\"LR\",X_vect,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ah8rfObsCc-u",
    "outputId": "821f3a84-053c-4972-c10d-cf767dc40f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8546311385678151\n",
      "Best Params:  {'C': 20, 'tol': 1e-08}\n",
      "CPU times: user 2min 15s, sys: 7min 5s, total: 9min 20s\n",
      "Wall time: 40min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_lr_smote = grid_search(\"LR\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['LR'] = grid_lr_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCMXN9M8Cc-u"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NPGHPCruCc-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8184510039849113\n",
      "Best Params:  {'alpha': 5.272631578947369e-06, 'penalty': 'l1'}\n",
      "CPU times: user 1.61 s, sys: 3.2 s, total: 4.81 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_per = grid_search(\"PER\",X_vect,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nZ1wmcmnCc-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8470214003772055\n",
      "Best Params:  {'alpha': 1e-08, 'penalty': 'l2'}\n",
      "CPU times: user 1.68 s, sys: 3.29 s, total: 4.96 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_per_smote = grid_search(\"PER\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['Perceptron'] = grid_per_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "La regression logistique n'est qu'un perceptron avec une sigmoid en fonction d'activation.\n",
    "On voit que la Regression Logistique a de meilleures performances à l'issue de la recherche d'hyperparamètres mais pas de loin. Par ailleurs le temps d'entrainement est considérablement plus élevé pour la regression logistique (du au calcul de l'exponentiel). Nous verrons par la suite quel modèle il est préférable de conserver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cy0mgWVCc-v"
   },
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9K-4Ufu3Cc-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83118297 0.86733725        nan\n",
      " 0.82688254        nan        nan 0.83113438        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8673372513001938\n",
      "Best Params:  {'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "CPU times: user 4.5 s, sys: 37.6 ms, total: 4.54 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_svc = grid_search(\"SVC\",X_vect,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "l4IjTNIiCc-w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.86085595 0.88400035        nan\n",
      " 0.85202663        nan        nan 0.86081901        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8840003539564666\n",
      "Best Params:  {'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "CPU times: user 3.15 s, sys: 53.9 ms, total: 3.2 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_svc_smote = grid_search(\"SVC\",X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SVC'] = grid_svc_smote.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charging the best parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ct7BBebdCc-w",
    "outputId": "a7c78c52-cb68-4e11-9490-fb43ef8b6189"
   },
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "data_sgd = data['SGD']\n",
    "data_rf = data['RF']\n",
    "data_gb = data['GB']\n",
    "data_lr = data['LR']\n",
    "data_per = data['Perceptron']\n",
    "data_svc = data['SVC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on all training data and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model,X_train_pred,y_train_pred):\n",
    "    predictions_train = model.predict(X_train_pred)\n",
    "    predictions_test = model.predict(X_vect_test)\n",
    "    accuracy_train = accuracy_score(y_train_pred,predictions_train )\n",
    "    accuracy_test = accuracy_score(y_test,predictions_test )\n",
    "    \n",
    "    print(f\"train_accuracy : {accuracy_train} \\ntest_accuracy : {accuracy_test}  \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FozzlotYCc-w",
    "outputId": "82bdacbd-ae58-49a0-faaf-c3ab0308b5fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1, penalty='l1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd_best = SGDClassifier()\n",
    "model_sgd_best.set_params(**data_sgd,n_jobs=-1) \n",
    "\n",
    "model_sgd_best_smote = SGDClassifier()\n",
    "model_sgd_best_smote.set_params(**data_sgd,n_jobs=-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 877 ms, sys: 905 ms, total: 1.78 s\n",
      "Wall time: 286 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1, penalty='l1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_sgd_best.fit(X_vect,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 937 ms, sys: 973 ms, total: 1.91 s\n",
      "Wall time: 318 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1, penalty='l1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_sgd_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9402774740627354 \n",
      "test_accuracy : 0.8807266982622433  \n"
     ]
    }
   ],
   "source": [
    "testing(model_sgd_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9344083638110016 \n",
      "test_accuracy : 0.8741442864665614  \n"
     ]
    }
   ],
   "source": [
    "testing(model_sgd_best_smote,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "lGouwXZ_Cc-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=600, max_features='log2',\n",
       "                       min_samples_split=32, n_jobs=-1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_best = RandomForestClassifier()\n",
    "model_rf_best.set_params(**data_rf,n_jobs=-1)\n",
    "\n",
    "model_rf_best_smote = RandomForestClassifier()\n",
    "model_rf_best_smote.set_params(**data_rf,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bdEu7AlyCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 142 ms, total: 20.5 s\n",
      "Wall time: 1.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=600, max_features='log2',\n",
       "                       min_samples_split=32, n_jobs=-1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf_best.fit(X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 s, sys: 170 ms, total: 31.6 s\n",
      "Wall time: 2.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=600, max_features='log2',\n",
       "                       min_samples_split=32, n_jobs=-1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yWtUmtDsCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9864664577107175 \n",
      "test_accuracy : 0.690626645602949  \n"
     ]
    }
   ],
   "source": [
    "testing(model_rf_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.974214045587203 \n",
      "test_accuracy : 0.6837809373354397  \n"
     ]
    }
   ],
   "source": [
    "testing(model_rf_best_smote,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, n_estimators=800)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb_best = GradientBoostingClassifier()\n",
    "model_gb_best.set_params(**data_gb)\n",
    "\n",
    "model_gb_best_smote = GradientBoostingClassifier()\n",
    "model_gb_best_smote.set_params(**data_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 59s, sys: 0 ns, total: 8min 59s\n",
      "Wall time: 8min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, n_estimators=800)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_gb_best.fit(X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 51s, sys: 0 ns, total: 11min 51s\n",
      "Wall time: 11min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, n_estimators=800)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_gb_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9167334839759944 \n",
      "test_accuracy : 0.8299104791995787  \n"
     ]
    }
   ],
   "source": [
    "testing(model_gb_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9134803649931656 \n",
      "test_accuracy : 0.8243812532912059  \n"
     ]
    }
   ],
   "source": [
    "testing(model_gb_best_smote,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000, n_jobs=-1, tol=1e-08)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_best = LogisticRegression(max_iter=1000)\n",
    "model_lr_best.set_params(**data_lr,n_jobs=-1)\n",
    "\n",
    "model_lr_best_smote = LogisticRegression(max_iter=1000)\n",
    "model_lr_best_smote.set_params(**data_lr, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.8 ms, sys: 221 ms, total: 316 ms\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000, n_jobs=-1, tol=1e-08)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_best.fit(X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 ms, sys: 8.27 ms, total: 18.4 ms\n",
      "Wall time: 16.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000, n_jobs=-1, tol=1e-08)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9846927618631096 \n",
      "test_accuracy : 0.8299104791995787  \n"
     ]
    }
   ],
   "source": [
    "testing(model_lr_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9814548006945214 \n",
      "test_accuracy : 0.8275408109531333  \n"
     ]
    }
   ],
   "source": [
    "testing(model_lr_best_smote,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=1e-08, n_jobs=-1, penalty='l2')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_per_best = Perceptron()\n",
    "model_per_best.set_params(**data_per,n_jobs=-1)\n",
    "\n",
    "model_per_best_smote = Perceptron()\n",
    "model_per_best_smote.set_params(**data_per,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 1.24 s, total: 1.68 s\n",
      "Wall time: 141 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=1e-08, n_jobs=-1, penalty='l2')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_per_best.fit(X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 484 ms, sys: 945 ms, total: 1.43 s\n",
      "Wall time: 162 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=1e-08, n_jobs=-1, penalty='l2')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_per_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9813640449984207 \n",
      "test_accuracy : 0.80173775671406  \n"
     ]
    }
   ],
   "source": [
    "testing(model_per_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9819165835457534 \n",
      "test_accuracy : 0.7877830437072143  \n"
     ]
    }
   ],
   "source": [
    "testing(model_per_best_smote,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=10000, penalty='l1')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc_best = LinearSVC(max_iter=10000)\n",
    "model_svc_best.set_params(**data_svc)\n",
    "\n",
    "model_svc_best_smote = LinearSVC(max_iter=10000)\n",
    "model_svc_best_smote.set_params(**data_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.29 s, sys: 1.92 ms, total: 4.29 s\n",
      "Wall time: 4.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=10000, penalty='l1')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc_best.fit(X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 s, sys: 4.81 ms, total: 2.88 s\n",
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=10000, penalty='l1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc_best_smote.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9481983623684914 \n",
      "test_accuracy : 0.8730911005792522  \n"
     ]
    }
   ],
   "source": [
    "testing(model_svc_best,X_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9525287228933467 \n",
      "test_accuracy : 0.8659820958399157  \n"
     ]
    }
   ],
   "source": [
    "testing(model_svc_best_smote,X_train_smote,y_train_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "aSjG01FhCc-x"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "86JLNLKor1AL"
   },
   "outputs": [],
   "source": [
    "clf1 = model_sgd_best_smote\n",
    "\n",
    "clf2 = model_rf_best_smote\n",
    "\n",
    "clf3 = model_gb_best_smote\n",
    "\n",
    "clf4 = model_lr_best_smote\n",
    "\n",
    "clf5 = model_per_best_smote\n",
    "\n",
    "clf6 = model_svc_best_smote\n",
    "\n",
    "\n",
    "eclf1 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('rf', clf2), ('gb', clf3), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n",
    "\n",
    "eclf2 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 46s, sys: 2.48 s, total: 11min 48s\n",
      "Wall time: 12min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                            n_jobs=-1, penalty='l1')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(criterion='entropy',\n",
       "                                                     max_depth=600,\n",
       "                                                     max_features='log2',\n",
       "                                                     min_samples_split=32,\n",
       "                                                     n_jobs=-1)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                                         n_estimators=800)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=20, max_iter=1000, n_jobs=-1,\n",
       "                                                 tol=1e-08)),\n",
       "                             ('per',\n",
       "                              Perceptron(alpha=1e-08, n_jobs=-1, penalty='l2')),\n",
       "                             ('svc',\n",
       "                              LinearSVC(dual=False, max_iter=10000,\n",
       "                                        penalty='l1'))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf1.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9753038531161107 \n",
      "test_accuracy : 0.8659820958399157  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf1,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.25 s, sys: 2.19 s, total: 6.44 s\n",
      "Wall time: 20.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                            n_jobs=-1, penalty='l1')),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=20, max_iter=1000, n_jobs=-1,\n",
       "                                                 tol=1e-08)),\n",
       "                             ('per',\n",
       "                              Perceptron(alpha=1e-08, n_jobs=-1, penalty='l2')),\n",
       "                             ('svc',\n",
       "                              LinearSVC(dual=False, max_iter=10000,\n",
       "                                        penalty='l1'))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf2.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9697624589013263 \n",
      "test_accuracy : 0.8570300157977883  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf2,X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_perso = [\"I think covid is the most horrible threat we ever faced\",\n",
    "                \"I love covid, thanks to it I can see my family much more often and I don't have to comute as much\",\n",
    "                \"I would love to come to your birthday party, but I got covid, I have to stay confined\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perso_vect = vectorizer.transform(tests_perso)\n",
    "predictions_out = eclf2.predict(test_perso_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main_notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "822dd2d5dd360abba25557036e653898358cd5c8dbb7b3b755070434497e6489"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
