{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "d9HjnVDmssa8"
   },
   "outputs": [],
   "source": [
    "# from os import chdir\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# chdir(\"/content/drive/MyDrive/Eliott/files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v-9SGvosr0_w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 19:21:44.429057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-31 19:21:44.429077: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train = 'Corona_NLP_train.csv'\n",
    "file_name_test = 'Corona_NLP_test.csv'\n",
    "X_train, y_train = pp.prepare_dataframe(file_name_train,lemmatising=False)\n",
    "X_test, y_test = pp.prepare_dataframe(file_name_test,lemmatising=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève : \n",
    "- Les URLS\n",
    "- Hashtags\n",
    "- Mentions\n",
    "- Mots réservés\n",
    "- Emojis et smileys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 35525 mots sans lemmatisation\n",
    "- 30794 avec lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMY7FfWTr1AI"
   },
   "source": [
    "# Recherche d'Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', GradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(max_iter=1000)),\n",
    "])\n",
    "\n",
    "pipeline_per = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', Perceptron()),\n",
    "])\n",
    "\n",
    "pipeline_svc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC(max_iter=10000)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_params = {\n",
    "    \"SGD\" : { \"model\" : pipeline_sgd,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__alpha': np.linspace(1e-7, 1e-4, 20),  \n",
    "                        }\n",
    "    },\n",
    "    \"GB\" : { \"model\" : pipeline_gb,\n",
    "              \"params\" : {\n",
    "                    \"clf__learning_rate\": [0.01, 0.1, 0.2],\n",
    "                    \"clf__n_estimators\":[10,50,100,200,400,800]\n",
    "                        }\n",
    "    },\n",
    "    \"RF\" : { \"model\" : pipeline_rf,\n",
    "              \"params\" : {\n",
    "                    'clf__n_estimators': [10, 100],   \n",
    "                    'clf__max_depth': [10 ,150,300,600],\n",
    "                    'clf__min_samples_leaf': [1, 2, 3],   \n",
    "                    'clf__min_samples_split': [4, 8, 16, 32],\n",
    "                    'clf__max_features': ['log2', 'sqrt'],\n",
    "                    'clf__criterion': ['gini', 'entropy'],\n",
    "                    'clf__warm_start': [True, False] \n",
    "                        }\n",
    "    },\n",
    "    \"LR\" : { \"model\" : pipeline_lr,\n",
    "              \"params\" : {\n",
    "                    'clf__C': [100, 80, 40,20,10, 1.0],\n",
    "                    'clf__tol': np.linspace(1e-8,1e-4,15)\n",
    "                        }\n",
    "    },\n",
    "    \"PER\" : { \"model\" : pipeline_per,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__alpha': np.linspace(1e-8, 1e-4, 20),\n",
    "                        }\n",
    "    },\n",
    "    \"SVC\" : { \"model\" : pipeline_svc,\n",
    "              \"params\" : {\n",
    "                    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                    'clf__loss': ['hinge', 'squared_hinge'],\n",
    "                    'clf__dual' : [False,True]\n",
    "                        }\n",
    "    }\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "En34oFshCc-r"
   },
   "outputs": [],
   "source": [
    "def grid_Search(model_name,subset=-1):\n",
    "\n",
    "    model = models_and_params[model_name][\"model\"]\n",
    "    parameters = models_and_params[model_name][\"params\"]\n",
    "\n",
    "    grid_clf = GridSearchCV(model, parameters,  scoring='accuracy', verbose=1 ,n_jobs=-1)\n",
    "    \n",
    "    if subset==-1:\n",
    "        grid_clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        grid_clf.fit(X_train[:subset], y_train[:subset])\n",
    "\n",
    "\n",
    "    print(\"Best Score: \", grid_clf.best_score_)\n",
    "    print(\"Best Params: \", grid_clf.best_params_)\n",
    "\n",
    "    return grid_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Hyperparameters in JSON\n",
    "\n",
    "We will first load old weights and updates only if needed. Then we can use the model with best params in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    dico = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.877785107829688\n",
      "Best Params:  {'clf__alpha': 1.0615789473684212e-05, 'clf__penalty': 'l1'}\n",
      "CPU times: user 8.1 s, sys: 6.88 s, total: 15 s\n",
      "Wall time: 47.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_sgd = grid_Search(\"SGD\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SGD'] = grid_sgd.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-R5-LqYCc-s"
   },
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Score:  0.8184027643721461\n",
      "Best Params:  {'clf__learning_rate': 0.2, 'clf__n_estimators': 800}\n",
      "CPU times: user 9min 8s, sys: 1.27 s, total: 9min 10s\n",
      "Wall time: 40min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_gb = grid_Search(\"GB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['GB'] = grid_gb.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf8DtN5iCc-t"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "P5bHoZ9pCc-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n",
      "Best Score:  0.6937577179543217\n",
      "Best Params:  {'clf__criterion': 'gini', 'clf__max_depth': 600, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 32, 'clf__n_estimators': 100, 'clf__warm_start': False}\n",
      "CPU times: user 1min 26s, sys: 49 s, total: 2min 15s\n",
      "Wall time: 34min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf = grid_Search(\"RF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['RF'] = grid_rf.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hybcOGPZCc-t"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NKt3pLZBCc-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Score:  0.8230920602963577\n",
      "Best Params:  {'clf__C': 10, 'clf__tol': 1e-08}\n",
      "CPU times: user 2min 10s, sys: 5min 41s, total: 7min 51s\n",
      "Wall time: 30min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_lr = grid_Search(\"LR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['LR'] = grid_lr.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCMXN9M8Cc-u"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NPGHPCruCc-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Score:  0.8128628567555942\n",
      "Best Params:  {'clf__alpha': 5.272631578947369e-06, 'clf__penalty': 'l1'}\n",
      "CPU times: user 7.6 s, sys: 3.57 s, total: 11.2 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_per = grid_Search(\"PER\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['Perceptron'] = grid_per.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "La regression logistique n'est qu'un perceptron avec une sigmoid en fonction d'activation.\n",
    "On voit que la Regression Logistique a de meilleures performances à l'issue de la recherche d'hyperparamètres mais pas de loin. Par ailleurs le temps d'entrainement est considérablement plus élevé pour la regression logistique (du au calcul de l'exponentiel). Nous verrons par la suite quel modèle il est préférable de conserver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cy0mgWVCc-v"
   },
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9K-4Ufu3Cc-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/eliott/envs/RNenv/lib64/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83094003 0.86896516        nan\n",
      " 0.82693114        nan        nan 0.83091573        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8689651633428769\n",
      "Best Params:  {'clf__dual': False, 'clf__loss': 'squared_hinge', 'clf__penalty': 'l1'}\n",
      "CPU times: user 6.25 s, sys: 102 ms, total: 6.35 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_svc = grid_Search(\"SVC\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SVC'] = grid_svc.best_params_\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charging the best parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ct7BBebdCc-w",
    "outputId": "a7c78c52-cb68-4e11-9490-fb43ef8b6189"
   },
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "data_sgd = data['SGD']\n",
    "data_rf = data['RF']\n",
    "data_gb = data['GB']\n",
    "data_lr = data['LR']\n",
    "data_per = data['Perceptron']\n",
    "data_svc = data['SVC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on all training data and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model):\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train,predictions_train )\n",
    "    accuracy_test = accuracy_score(y_test,predictions_test )\n",
    "    \n",
    "    print(f\"train_accuracy : {accuracy_train} \\ntest_accuracy : {accuracy_test}  \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FozzlotYCc-w",
    "outputId": "82bdacbd-ae58-49a0-faaf-c3ab0308b5fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1,\n",
       "                               penalty='l1'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd_best = pipeline_sgd\n",
    "model_sgd_best.set_params(**data_sgd,clf__n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 996 ms, total: 2.48 s\n",
      "Wall time: 871 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.0615789473684212e-05, n_jobs=-1,\n",
       "                               penalty='l1'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Si on a fait la recherche avant, on prend le best modèle,\n",
    "\n",
    "Sinon, on reconstruit le modèle avec les best paramètres et on le fit à toutes les données d'entrainement. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model_sgd_best.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9414437398255461 \n",
      "test_accuracy : 0.8841495523959979  \n"
     ]
    }
   ],
   "source": [
    "testing(model_sgd_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lGouwXZ_Cc-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=600, max_features='sqrt',\n",
       "                                        min_samples_leaf=2,\n",
       "                                        min_samples_split=32, n_jobs=-1))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_best = pipeline_rf\n",
    "model_rf_best.set_params(**data_rf,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bdEu7AlyCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 84.9 ms, total: 21.4 s\n",
      "Wall time: 2.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=600, max_features='sqrt',\n",
       "                                        min_samples_leaf=2,\n",
       "                                        min_samples_split=32, n_jobs=-1))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yWtUmtDsCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.8690137765143232 \n",
      "test_accuracy : 0.6901000526592944  \n"
     ]
    }
   ],
   "source": [
    "testing(model_rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb_best = pipeline_gb\n",
    "model_gb_best.set_params(**data_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 56s, sys: 0 ns, total: 8min 56s\n",
      "Wall time: 8min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_gb_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9167334839759944 \n",
      "test_accuracy : 0.8307003686150606  \n"
     ]
    }
   ],
   "source": [
    "testing(model_gb_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, max_iter=1000, n_jobs=-1,\n",
       "                                    tol=1e-08))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_best = pipeline_lr\n",
    "model_lr_best.set_params(**data_lr,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 610 ms, sys: 170 ms, total: 780 ms\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, max_iter=1000, n_jobs=-1,\n",
       "                                    tol=1e-08))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9755327161843672 \n",
      "test_accuracy : 0.833070036861506  \n"
     ]
    }
   ],
   "source": [
    "testing(model_lr_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, n_jobs=-1,\n",
       "                            penalty='l1'))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_per_best = pipeline_per\n",
    "model_per_best.set_params(**data_per,clf__n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 1.16 s, total: 2.23 s\n",
      "Wall time: 727 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, n_jobs=-1,\n",
       "                            penalty='l1'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_per_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9055324732123332 \n",
      "test_accuracy : 0.822538177988415  \n"
     ]
    }
   ],
   "source": [
    "testing(model_per_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc_best = pipeline_svc\n",
    "model_svc_best.set_params(**data_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 8.3 ms, total: 4.68 s\n",
      "Wall time: 4.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9481983623684914 \n",
      "test_accuracy : 0.8730911005792522  \n"
     ]
    }
   ],
   "source": [
    "testing(model_svc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aSjG01FhCc-x"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "86JLNLKor1AL"
   },
   "outputs": [],
   "source": [
    "clf1 = model_sgd_best\n",
    "\n",
    "clf2 = model_rf_best\n",
    "\n",
    "clf3 = model_gb_best\n",
    "\n",
    "clf4 = model_lr_best\n",
    "\n",
    "clf5 = model_per_best\n",
    "\n",
    "clf6 = model_svc_best\n",
    "\n",
    "\n",
    "eclf1 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('rf', clf2), ('gb', clf3), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n",
    "\n",
    "eclf2 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 53s, sys: 2.19 s, total: 8min 55s\n",
      "Wall time: 9min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('rf',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               RandomForestClassifier(max_depth=600,\n",
       "                                                                      max_features='sqrt',\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=32,\n",
       "                                                                      n_jobs=-1))])),\n",
       "                             ('gb',\n",
       "                              Pipeline(steps=[(...\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9578686493184635 \n",
      "test_accuracy : 0.8717746182201158  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.5 s, sys: 2.08 s, total: 9.58 s\n",
      "Wall time: 16.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.0615789473684212e-05,\n",
       "                                                             n_jobs=-1,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('lr',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9575527856743689 \n",
      "test_accuracy : 0.8688783570300158  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_perso = [\"I think covid is the most horrible threat we ever faced\",\n",
    "                \"I love covid, thanks to it I can see my family much more often and I don't have to comute as much\",\n",
    "                \"I would love to come to your birthday party, but I got covid, I have to stay confined\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_out = eclf2.predict(tests_perso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main_notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "822dd2d5dd360abba25557036e653898358cd5c8dbb7b3b755070434497e6489"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
