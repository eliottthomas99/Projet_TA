{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d9HjnVDmssa8"
   },
   "outputs": [],
   "source": [
    "# from os import chdir\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# chdir(\"/content/drive/MyDrive/Eliott/files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v-9SGvosr0_w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:19:04.527142: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-28 15:19:04.527167: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'iter' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/main_notebook.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/main_notebook.ipynb#ch0000002?line=0'>1</a>\u001b[0m file_name_train \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCorona_NLP_train.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/main_notebook.ipynb#ch0000002?line=1'>2</a>\u001b[0m file_name_test \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCorona_NLP_test.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/main_notebook.ipynb#ch0000002?line=2'>3</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39;49mprepare_dataframe(file_name_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/main_notebook.ipynb#ch0000002?line=3'>4</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mprepare_dataframe(file_name_test)\n",
      "File \u001b[0;32m~/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py:88\u001b[0m, in \u001b[0;36mprepare_dataframe\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=83'>84</a>\u001b[0m \u001b[39m# Lemmatisation\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=85'>86</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=87'>88</a>\u001b[0m X_df\u001b[39m.\u001b[39;49mapply(lemmatisation , args\u001b[39m=\u001b[39;49m(nlp,)) \n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=90'>91</a>\u001b[0m \u001b[39mprint\u001b[39m(X_df)\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=95'>96</a>\u001b[0m \u001b[39mreturn\u001b[39;00m X_df, y_df\n",
      "File \u001b[0;32m~/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4322'>4323</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4323'>4324</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4329'>4330</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4330'>4331</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4331'>4332</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4430'>4431</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4431'>4432</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/series.py?line=4432'>4433</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/envs/RNenv/lib64/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py:138\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[0;32m--> <a href='file:///home/eliott/envs/RNenv/lib64/python3.10/site-packages/pandas/core/apply.py?line=137'>138</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py:48\u001b[0m, in \u001b[0;36mlemmatisation\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=44'>45</a>\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m lemme\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=45'>46</a>\u001b[0m out\u001b[39m=\u001b[39mout[:\u001b[39mlen\u001b[39m(out)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=47'>48</a>\u001b[0m \u001b[39miter\u001b[39m\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39miter\u001b[39m\u001b[39m%\u001b[39m\u001b[39m100\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='file:///home/eliott/pCloudDrive/ELIOTTDOC/3A_ENSSAT/NotesCours/Hiver/TA/Projet_TA/Projet_TA/preprocessing.py?line=49'>50</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39miter\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'iter' referenced before assignment"
     ]
    }
   ],
   "source": [
    "file_name_train = 'Corona_NLP_train.csv'\n",
    "file_name_test = 'Corona_NLP_test.csv'\n",
    "X_train, y_train = pp.prepare_dataframe(file_name_train)\n",
    "X_test, y_test = pp.prepare_dataframe(file_name_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève : \n",
    "- Les URLS\n",
    "- Hashtags\n",
    "- Mentions\n",
    "- Mots réservés\n",
    "- Emojis et smileys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMY7FfWTr1AI"
   },
   "source": [
    "# Recherche d'Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "En34oFshCc-r"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gw_ctOGer1AJ",
    "outputId": "64711ad4-134c-4740-93ae-81cd1d39bf18"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grid_params = {\n",
    "  'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "  'clf__alpha': np.linspace(1e-7, 1e-4, 20),  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pipeline_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "sgd_clf = GridSearchCV(pipeline_clf, grid_params,verbose=1, scoring='accuracy' ,n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "CPU times: user 8.46 s, sys: 7.09 s, total: 15.6 s\n",
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sgd_best = sgd_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rNZdWzmECc-s",
    "outputId": "de030e87-d92c-4f72-9081-fd094f7dd765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8798018707630579\n",
      "Best Params:  {'clf__alpha': 1.5873684210526315e-05, 'clf__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", sgd_clf.best_score_)\n",
    "print(\"Best Params: \", sgd_clf.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "#text_clf.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-R5-LqYCc-s"
   },
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "Js4osvIVCc-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "eADXIJhICc-s"
   },
   "outputs": [],
   "source": [
    "GB_param = {\n",
    "    \"gb_clf__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"gb_clf__n_estimators\":[10,50,100,200,400,800]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "CYWf_gRmCc-s"
   },
   "outputs": [],
   "source": [
    "pipeline_gradient_boosting = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('gb_clf', GradientBoostingClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "gb_clf = GridSearchCV(pipeline_gradient_boosting, GB_param, scoring='accuracy', verbose=1 ,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "L58wVHqXCc-s",
    "outputId": "3f0828a6-faf9-4251-ac38-783416ab50e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: user 9min 29s, sys: 258 ms, total: 9min 29s\n",
      "Wall time: 46min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset = X_train.shape[0]\n",
    "\n",
    "gb_best = gb_clf.fit(X_train[:subset], y_train[:subset])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "FPjgbNPZCc-s",
    "outputId": "77ceb4a5-b879-4f76-a949-9b0e0582648f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8194232669897714\n",
      "Best Params:  {'gb_clf__learning_rate': 0.2, 'gb_clf__n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", gb_clf.best_score_)\n",
    "print(\"Best Params: \", gb_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf8DtN5iCc-t"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "P5bHoZ9pCc-t"
   },
   "outputs": [],
   "source": [
    "randForest_param = {\n",
    "    'rf_clf__n_estimators': [10, 100],   \n",
    "    'rf_clf__max_depth': [10 ,150,300,600],\n",
    "    'rf_clf__min_samples_leaf': [1, 2, 3],   \n",
    "    'rf_clf__min_samples_split': [4, 8, 16, 32],\n",
    "    'rf_clf__max_features': ['log2', 'sqrt'],\n",
    "    'rf_clf__criterion': ['gini', 'entropy'],\n",
    "    'rf_clf__warm_start': [True, False] \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pipeline_random_forest = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('rf_clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "rf_clf = GridSearchCV(pipeline_random_forest, randForest_param, scoring='accuracy', verbose=1 ,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "a8oiQPa1Cc-t",
    "outputId": "6d19aab7-4f19-4f68-c15e-e875728e885f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n",
      "CPU times: user 1min 34s, sys: 8.71 s, total: 1min 43s\n",
      "Wall time: 42min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset = X_train.shape[0]\n",
    "\n",
    "rf_best = rf_clf.fit(X_train[:subset], y_train[:subset])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "-iAg4caBCc-t",
    "outputId": "779675e0-c1bd-4b6f-a51a-3ce6c2b5e90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.6925428813940141\n",
      "Best Params:  {'rf_clf__criterion': 'entropy', 'rf_clf__max_depth': 300, 'rf_clf__max_features': 'sqrt', 'rf_clf__min_samples_leaf': 2, 'rf_clf__min_samples_split': 32, 'rf_clf__n_estimators': 100, 'rf_clf__warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", rf_clf.best_score_)\n",
    "print(\"Best Params: \", rf_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hybcOGPZCc-t"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "1vYHWTnnCc-t"
   },
   "outputs": [],
   "source": [
    "LogisticRegression_param = {\n",
    "    'lr_clf__C': [100, 80, 40,20,10, 1.0],\n",
    "    'lr_clf__tol': np.linspace(1e-8,1e-4,15)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "K2zGzzSbCc-u"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                       \n",
    "                     ('lr_clf', LogisticRegression(max_iter=1000)),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "NKt3pLZBCc-u"
   },
   "outputs": [],
   "source": [
    "lr_clf = GridSearchCV(pipeline_lr, LogisticRegression_param,  scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "ah8rfObsCc-u",
    "outputId": "821f3a84-053c-4972-c10d-cf767dc40f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "CPU times: user 1min 55s, sys: 4min 27s, total: 6min 23s\n",
      "Wall time: 32min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_best = lr_clf.fit(X_train[:subset], y_train[:subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "WUqSxp-DCc-u",
    "outputId": "be7c2a1a-a3d9-451e-f042-d9cf9161eb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8230920602963577\n",
      "Best Params:  {'lr_clf__C': 10, 'lr_clf__tol': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", lr_clf.best_score_)\n",
    "print(\"Best Params: \", lr_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCMXN9M8Cc-u"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "NPGHPCruCc-v"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "nZ1wmcmnCc-v"
   },
   "outputs": [],
   "source": [
    "per_params = {\n",
    "  'per_clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "  'per_clf__alpha': np.linspace(1e-8, 1e-4, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "i084u0cSCc-v"
   },
   "outputs": [],
   "source": [
    "pipeline_perceptron = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                       \n",
    "                     ('per_clf', Perceptron()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "4bXgV-wICc-v"
   },
   "outputs": [],
   "source": [
    "per_clf = GridSearchCV(pipeline_perceptron, per_params,  scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "-Y8KKKNqCc-v",
    "outputId": "9f7531d6-8757-4dfa-9aaf-65b27ec3ff87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "CPU times: user 7.8 s, sys: 3.47 s, total: 11.3 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "per_best = per_clf.fit(X_train[:subset], y_train[:subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "9dTgtWPwCc-v",
    "outputId": "850fa25d-7e8e-4673-8d08-aceccc172a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8128628567555942\n",
      "Best Params:  {'per_clf__alpha': 5.272631578947369e-06, 'per_clf__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", per_clf.best_score_)\n",
    "print(\"Best Params: \", per_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "La regression logistique n'est qu'un perceptron avec une sigmoid en fonction d'activation.\n",
    "On voit que la Regression Logistique a de meilleures performances à l'issue de la recherche d'hyperparamètres mais pas de loin. Par ailleurs le temps d'entrainement est considérablement plus élevé pour la regression logistique (du au calcul de l'exponentiel). Nous verrons par la suite quel modèle il est préférable de conserver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cy0mgWVCc-v"
   },
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "9K-4Ufu3Cc-v"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "l4IjTNIiCc-w"
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "  'svc_clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "  'svc_clf__loss': ['hinge', 'squared_hinge'],\n",
    "  'svc_clf__dual' : [False,True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "QsauLn7wCc-w"
   },
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                       \n",
    "                     ('svc_clf', LinearSVC(max_iter=10000)),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "1CW5MyCxCc-w"
   },
   "outputs": [],
   "source": [
    "svc_clf = GridSearchCV(pipeline_svc, svc_params,  scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "D-EHrYKACc-w",
    "outputId": "959d23ee-fd5c-4bb0-b465-e7bd5cdc0620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='hinge' is not supported, Parameters: penalty='elasticnet', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/eliott/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/eliott/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83094003 0.86896516        nan\n",
      " 0.82693114        nan        nan 0.83091573        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.8 s, sys: 151 ms, total: 6.95 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_best = svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "aB2TUBujCc-w",
    "outputId": "5562d375-7e68-49c7-8109-4979babcddbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8689651633428769\n",
      "Best Params:  {'svc_clf__dual': False, 'svc_clf__loss': 'squared_hinge', 'svc_clf__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", svc_clf.best_score_)\n",
    "print(\"Best Params: \", svc_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Hyperparameters in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eqokclx8Cc-w"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    dico = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SGD'] = sgd_clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['RF'] = rf_clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['GB'] = gb_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['LR'] = lr_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['Perceptron'] = per_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['SVC'] = svc_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "okUYBXphCc-w"
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(dico, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charging the best parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "ct7BBebdCc-w",
    "outputId": "a7c78c52-cb68-4e11-9490-fb43ef8b6189"
   },
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "data_sgd = data['SGD']\n",
    "data_rf = data['RF']\n",
    "data_gb = data['GB']\n",
    "data_lr = data['LR']\n",
    "data_per = data['Perceptron']\n",
    "data_svc = data['SVC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on all training data and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model):\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train,predictions_train )\n",
    "    accuracy_test = accuracy_score(y_test,predictions_test )\n",
    "    \n",
    "    print(f\"train_accuracy : {accuracy_train} \\ntest_accuracy : {accuracy_test}  \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "FozzlotYCc-w",
    "outputId": "82bdacbd-ae58-49a0-faaf-c3ab0308b5fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.5873684210526315e-05, penalty='l1'))])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd = pipeline_clf\n",
    "model_sgd.set_params(**data_sgd) # clf__max_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 2.77 s, total: 4.46 s\n",
      "Wall time: 1.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=1.5873684210526315e-05, penalty='l1'))])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_sgd.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.923415214908764 \n",
      "test_accuracy : 0.882306477093207  \n"
     ]
    }
   ],
   "source": [
    "testing(model_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPAWdBLOCc-x"
   },
   "outputs": [],
   "source": [
    "f1score = f1_score(y_test, ad_best_ss.predict(X_test_ss), average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "lGouwXZ_Cc-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('rf_clf',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=300,\n",
       "                                        max_features='sqrt', min_samples_leaf=2,\n",
       "                                        min_samples_split=32,\n",
       "                                        warm_start=True))])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = pipeline_random_forest\n",
    "model_rf.set_params(**data_rf) # clf__max_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "bdEu7AlyCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 628 µs, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('rf_clf',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=300,\n",
       "                                        max_features='sqrt', min_samples_leaf=2,\n",
       "                                        min_samples_split=32,\n",
       "                                        warm_start=True))])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "yWtUmtDsCc-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.8715163884636878 \n",
      "test_accuracy : 0.6951026856240127  \n"
     ]
    }
   ],
   "source": [
    "testing(model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('gb_clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb = pipeline_gradient_boosting\n",
    "model_gb.set_params(**data_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 31s, sys: 5.85 ms, total: 9min 31s\n",
      "Wall time: 9min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('gb_clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.2,\n",
       "                                            n_estimators=800))])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9167334839759944 \n",
      "test_accuracy : 0.8299104791995787  \n"
     ]
    }
   ],
   "source": [
    "testing(model_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('lr_clf', LogisticRegression(C=10, max_iter=1000, tol=1e-08))])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = pipeline_lr\n",
    "model_lr.set_params(**data_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 3min 54s, total: 5min 11s\n",
      "Wall time: 22.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('lr_clf', LogisticRegression(C=10, max_iter=1000, tol=1e-08))])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9755327161843672 \n",
      "test_accuracy : 0.833070036861506  \n"
     ]
    }
   ],
   "source": [
    "testing(model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('per_clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, penalty='l1'))])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_per = pipeline_perceptron\n",
    "model_per.set_params(**data_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 2.73 s, total: 4.26 s\n",
      "Wall time: 1.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('per_clf',\n",
       "                 Perceptron(alpha=5.272631578947369e-06, penalty='l1'))])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_per.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9055324732123332 \n",
      "test_accuracy : 0.822538177988415  \n"
     ]
    }
   ],
   "source": [
    "testing(model_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('svc_clf',\n",
       "                 LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = pipeline_svc\n",
    "model_svc.set_params(**data_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.51 s, sys: 6.3 ms, total: 5.52 s\n",
      "Wall time: 5.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('svc_clf',\n",
       "                 LinearSVC(dual=False, max_iter=10000, penalty='l1'))])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9481983623684914 \n",
      "test_accuracy : 0.8730911005792522  \n"
     ]
    }
   ],
   "source": [
    "testing(model_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "aSjG01FhCc-x"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "86JLNLKor1AL"
   },
   "outputs": [],
   "source": [
    "clf1 = model_sgd\n",
    "\n",
    "clf2 = model_rf\n",
    "\n",
    "clf3 = model_gb\n",
    "\n",
    "clf4 = model_lr\n",
    "\n",
    "clf5 = model_per\n",
    "\n",
    "clf6 = model_svc\n",
    "\n",
    "\n",
    "eclf1 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('rf', clf2), ('gb', clf3), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n",
    "\n",
    "eclf2 = VotingClassifier(\n",
    "     estimators=[('sgd', clf1), ('lr', clf4), ('per', clf5), ('svc', clf6)],\n",
    "     voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 2s, sys: 3min 55s, total: 14min 57s\n",
      "Wall time: 10min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.5873684210526315e-05,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('rf',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('rf_clf',\n",
       "                                               RandomForestClassifier(criterion='entropy',\n",
       "                                                                      max_depth=300,\n",
       "                                                                      max_features='sqrt',\n",
       "                                                                      min_samples_leaf=2,\n",
       "                                                                      min_samples_split=32,\n",
       "                                                                      warm_start=True))])),\n",
       "                             ('gb...\n",
       "                                                                          n_estimators=800))])),\n",
       "                             ('lr',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('lr_clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('per_clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('svc_clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9558276842335447 \n",
      "test_accuracy : 0.8699315429173249  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 4min 33s, total: 6min 8s\n",
      "Wall time: 33.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sgd',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('clf',\n",
       "                                               SGDClassifier(alpha=1.5873684210526315e-05,\n",
       "                                                             penalty='l1'))])),\n",
       "                             ('lr',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('lr_clf',\n",
       "                                               LogisticRegression(C=10,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  tol=1e-08))])),\n",
       "                             ('per',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('per_clf',\n",
       "                                               Perceptron(alpha=5.272631578947369e-06,\n",
       "                                                          penalty='l1'))])),\n",
       "                             ('svc',\n",
       "                              Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                              ('svc_clf',\n",
       "                                               LinearSVC(dual=False,\n",
       "                                                         max_iter=10000,\n",
       "                                                         penalty='l1'))]))])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eclf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 0.9555361177928421 \n",
      "test_accuracy : 0.8715113217482886  \n"
     ]
    }
   ],
   "source": [
    "testing(eclf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_perso = [\"I think covid is the most horrible threat we ever faced\",\n",
    "                \"I love covid, thanks to it I can see my family much more often and I don't have to comute as much\",\n",
    "                \"I would love to come to your birthday party, but I got covid, I have to stay confined\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_out = eclf2.predict(tests_perso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main_notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "822dd2d5dd360abba25557036e653898358cd5c8dbb7b3b755070434497e6489"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
